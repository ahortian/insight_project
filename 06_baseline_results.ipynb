{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import calendar\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "#from sklearn import linear_model\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# scaling the input feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from joblib import load\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = './data/processed/crime_data/fullTrainTestCrimeData_train_weather_by_hourgroup_police_rand_2019_06_27.csv'\n",
    "valid_fname = './data/processed/crime_data/fullTrainTestCrimeData_valid_weather_by_hourgroup_police_rand_2019_06_27.csv'\n",
    "tests_fname = './data/processed/crime_data/fullTrainTestCrimeData_tests_weather_by_hourgroup_police_rand_2019_06_27.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_fname)\n",
    "df_train = df_train.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# remove outliers\n",
    "ind_to_drop_outlier = df_train[df_train[\"Value\"]>60].index\n",
    "df_train = df_train.drop(ind_to_drop_outlier, axis=0)\n",
    "\n",
    "df_valid = pd.read_csv(valid_fname)\n",
    "df_valid = df_valid.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "df_test = pd.read_csv(tests_fname)\n",
    "df_test = df_test.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "df_train[\"Value_Occ\"] = df_train[\"Value\"].apply(lambda x: 1 if x>0 else x)\n",
    "df_valid[\"Value_Occ\"] = df_valid[\"Value\"].apply(lambda x: 1 if x>0 else x)\n",
    "df_test[\"Value_Occ\"]  = df_test[\"Value\"].apply(lambda x: 1 if x>0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train[[\"Hour_Grp\",\"DAY_OF_MONTH\",\"DAY_OF_WEEK_NUM\",\"MONTH\",\"Lat\",\"Long\"\n",
    "                    ,\"Temperature(F)\",\"Humidity(%)\",\"Wind Speed(mph)\",\"Precip.(in)\",\n",
    "                    \"closest_police_d\",\"closest_mbta_d\"]]\n",
    "\n",
    "x_valid = df_valid[[\"Hour_Grp\",\"DAY_OF_MONTH\",\"DAY_OF_WEEK_NUM\",\"MONTH\",\"Lat\",\"Long\"\n",
    "                    ,\"Temperature(F)\",\"Humidity(%)\",\"Wind Speed(mph)\",\"Precip.(in)\",\n",
    "                    \"closest_police_d\",\"closest_mbta_d\"]]\n",
    "\n",
    "x_test = df_test[[\"Hour_Grp\",\"DAY_OF_MONTH\",\"DAY_OF_WEEK_NUM\",\"MONTH\",\"Lat\",\"Long\"\n",
    "                    ,\"Temperature(F)\",\"Humidity(%)\",\"Wind Speed(mph)\",\"Precip.(in)\",\n",
    "                  \"closest_police_d\",\"closest_mbta_d\"]]\n",
    "\n",
    "y_train = df_train[[\"Value_Occ\"]]\n",
    "y_valid = df_valid[[\"Value_Occ\"]]\n",
    "y_test = df_test[[\"Value_Occ\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at data, how was it built? \n",
    "- See code: 03_data_prep_train_test_data.ipynb\n",
    "- train is evenly grids \n",
    "- valid and test are random around the train grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEAN\n",
    "### Calculate Mean Values\n",
    "- for a location, calculate the average over time\n",
    "- this is calculated on the training sample only\n",
    "    - think of it as a model which is trained on training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 24\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import calendar\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# parameters setup for segmenting the area\n",
    "grid_w = 0.5 # mi\n",
    "grid_deg = round((grid_w/111)*1.60934, 4)\n",
    "\n",
    "lat_dn = 42.2324\n",
    "lat_up = 42.3951\n",
    "lng_dn = -71.1787\n",
    "lng_up = -70.9636\n",
    "\n",
    "# start_day = datetime.datetime(2015,6,15)\n",
    "# last_day = datetime.datetime(2015,9,30)\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "fp = \"./data/raw/bos_land/bos_land.shp\"\n",
    "data_shapemap = gpd.read_file(fp)\n",
    "\n",
    "# Convert data to global lat long\n",
    "# EPSG 4326 = WGS84 = https://epsg.io/4326\n",
    "data_shapemap_geo = data_shapemap.to_crs(epsg=4326) \n",
    "multi_polygon = list(data_shapemap_geo[\"geometry\"][0])\n",
    "\n",
    "def in_MutiPolygon(lat, lng, multi_polygon):\n",
    "    is_inside = False\n",
    "    for polg in multi_polygon:\n",
    "        point = Point(lng, lat)\n",
    "        is_inside = polg.contains(point)\n",
    "        if is_inside:\n",
    "            return is_inside\n",
    "    return is_inside\n",
    "\n",
    "a = lat_dn\n",
    "lat_list=[]\n",
    "lat_list+=[round(a,4)]\n",
    "while a <= lat_up:\n",
    "    a+= grid_deg\n",
    "    lat_list += [round(a,4)] \n",
    "    \n",
    "b = lng_dn\n",
    "lng_list=[]\n",
    "lng_list+=[round(b,4)]\n",
    "while b <= lng_up:\n",
    "    b+= grid_deg\n",
    "    lng_list += [round(b,4)]\n",
    "print (len(lng_list),len(lat_list))\n",
    "\n",
    "hour_groups = [1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean values for Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count :  1\n",
      "count :  2\n",
      "count :  3\n",
      "count :  4\n",
      "count :  5\n",
      "count :  6\n",
      "count :  7\n",
      "count :  8\n",
      "count :  9\n",
      "count :  10\n",
      "count :  11\n",
      "count :  12\n",
      "count :  13\n",
      "count :  14\n",
      "count :  15\n",
      "count :  16\n",
      "count :  17\n",
      "count :  18\n",
      "count :  19\n",
      "count :  20\n",
      "count :  21\n",
      "count :  22\n",
      "count :  23\n",
      "count :  24\n",
      "count :  25\n",
      "count :  26\n",
      "count :  27\n",
      "count :  28\n",
      "count :  29\n",
      "count :  30\n",
      "count :  31\n"
     ]
    }
   ],
   "source": [
    "def create_mean_feature(df_train):\n",
    "    cnt = 0\n",
    "    data = []\n",
    "    for lng in lng_list:\n",
    "        cnt +=1 \n",
    "        print (\"count : \", cnt )\n",
    "        for lat in lat_list:\n",
    "            in_Bos = in_MutiPolygon(lat, lng, multi_polygon)\n",
    "            if in_Bos:\n",
    "                for this_hr in hour_groups:\n",
    "                    con1 = (df_train[\"Lat\"] < lat + 0.000001)\n",
    "                    con2 = (df_train[\"Lat\"] > lat - 0.000001)\n",
    "                    con3 = (df_train[\"Long\"] < lng + 0.000001)\n",
    "                    con4 = (df_train[\"Long\"] > lng - 0.000001)\n",
    "\n",
    "                    _mean = df_train[ con1&con2&con3&con4 & (df_train[\"Hour_Grp\"] == this_hr)][\"Value_Occ\"].mean()\n",
    "                    #print (cnt, lng, lat,  _mean)\n",
    "                    dat = { 'Lat': lat,'Long': lng, \n",
    "                            'Lat_int': int(lat*1000),'Long_int': int(lng*1000), \n",
    "                               'Hour_Grp':this_hr,\n",
    "                               'mean': round(_mean),\n",
    "                               'mean_raw': _mean,\n",
    "                              }\n",
    "                    data += [dat]\n",
    "    train_mean = pd.DataFrame(data)\n",
    "    return train_mean\n",
    "train_mean = create_mean_feature(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEAN prediction for the Test sample : real calculation \n",
    "   - since now the validate and test sample have random grid poits\n",
    "   - we need more caluclation to get mean of these sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_predict(inp_lat, inp_lng, inp_hr_gr, grid_deg, df_mean_in): \n",
    "    #tmp_df[\"Lat\"].iloc[0]\n",
    "    #tmp_df[\"Lat\"]\n",
    "    cond2 = df_mean_in[\"Lat\"] < (inp_lat + 1.1*grid_deg)\n",
    "    cond3 = df_mean_in[\"Lat\"] > (inp_lat - 1.1*grid_deg)\n",
    "    cond4 = df_mean_in[\"Long\"] < (inp_lng + 1.1*grid_deg)\n",
    "    cond5 = df_mean_in[\"Long\"] > (inp_lng - 1.1*grid_deg)\n",
    "    cond6 = df_mean_in[\"Hour_Grp\"] == inp_hr_gr\n",
    "    tmp_df = df_mean_in[cond2 & cond3 & cond4 & cond5 & cond6]\n",
    "    #print (inp_lat, inp_lng)\n",
    "    #print (tmp_df)\n",
    "    \n",
    "    min_dist = 200\n",
    "    dist = 0\n",
    "    y_dist = 0\n",
    "    x_dist = 0\n",
    "    mean_val = 0\n",
    "    \n",
    "    for i in range(tmp_df.shape[0]):\n",
    "        la = tmp_df[\"Lat\"].iloc[i]\n",
    "        ln = tmp_df[\"Long\"].iloc[i]\n",
    "        \n",
    "        y_dist = abs(inp_lat-la) *(111/1.60934)\n",
    "        x_dist = abs(inp_lng-ln) *(111/1.60934)\n",
    "        dist = math.sqrt((y_dist**2) + (x_dist**2))\n",
    "        \n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            mean_val = tmp_df[\"mean\"].iloc[i]\n",
    "            #print (\"min_dist \", min_dist, la, ln, mean_val)\n",
    "    \n",
    "    return mean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: This takes 8 minutes to finish\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "Elapsed time:  432.02577805519104\n"
     ]
    }
   ],
   "source": [
    "print (\"Warning: This takes 8 minutes to finish\")\n",
    "start_time = time.time()\n",
    "#df_test[\"mean\"] = 0\n",
    "test_sample_meanout = []\n",
    "for i in range(df_test.shape[0]):\n",
    "#for i in range(df_test[:500].shape[0]):\n",
    "    if i%10000 == 0: print (i)\n",
    "    _mean = get_mean_predict(df_test[\"Lat\"].iloc[i], df_test[\"Long\"].iloc[i], df_test[\"Hour_Grp\"].iloc[i], grid_deg, train_mean)\n",
    "    test_sample_meanout += [_mean]\n",
    "    #print (\"_mean \", _mean)\n",
    "print (\"Elapsed time: \", str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN f1_score      :  0.5527150217994452\n",
      "MEAN accuracy_score:  0.8082738702004757\n"
     ]
    }
   ],
   "source": [
    "y_test_mean = pd.DataFrame({'test_set_cal_mean': test_sample_meanout})\n",
    "#print (y_test_mean.head())\n",
    "print ( \"MEAN f1_score      : \", f1_score(y_test, y_test_mean))\n",
    "print ( \"MEAN accuracy_score: \", accuracy_score(y_test, y_test_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results of calculation for later use\n",
    "y_test_mean.to_csv('./data/processed/crime_data/test_cal_mean_police_rand_2019_06_27.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from saved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mean = pd.read_csv(\"./data/processed/crime_data/test_cal_mean_police_rand_2019_06_27.csv\")\n",
    "y_test_mean = y_test_mean.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN f1_score      :  0.5527150217994452\n",
      "MEAN accuracy_score:  0.8082738702004757\n"
     ]
    }
   ],
   "source": [
    "y_test_true = df_test[[\"Value_Occ\"]]\n",
    "print ( \"MEAN f1_score      : \", f1_score(y_test, y_test_mean))\n",
    "print ( \"MEAN accuracy_score: \", accuracy_score(y_test, y_test_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
